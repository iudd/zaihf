#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Zai Provider - çº¯HTTPè¯·æ±‚ï¼Œä¸ç®¡ç†æµè§ˆå™¨

æ¶æ„åŸåˆ™ï¼š
- æ¥æ”¶Tokenï¼Œæ‰§è¡ŒHTTPè¯·æ±‚
- ä¸ç®¡ç†Tokenç”Ÿå‘½å‘¨æœŸ
- ä¸æ“ä½œæµè§ˆå™¨
- åªè´Ÿè´£ä¸Zai APIé€šä¿¡
"""

import asyncio
import json
import time
import uuid
import urllib.parse
import httpx
import re
import base64
from loguru import logger
from app.core.config import settings
from app.utils.sse_utils import create_chat_completion_chunk
from app.providers.base_provider import BaseProvider

class ZaiProvider(BaseProvider):
    """
    Zai Provider - åªè´Ÿè´£HTTPè¯·æ±‚ï¼Œä¸ç®¡ç†æµè§ˆå™¨
    
    æ¶æ„åŸåˆ™ï¼š
    - æ¥æ”¶Tokenï¼Œæ‰§è¡ŒHTTPè¯·æ±‚
    - ä¸ç®¡ç†Tokenç”Ÿå‘½å‘¨æœŸ
    - ä¸æ“ä½œæµè§ˆå™¨
    - åªè´Ÿè´£ä¸Zai APIé€šä¿¡
    """
    
    def __init__(self):
        self.base_url = settings.ZAI_BASE_URL
        self.default_model = settings.DEFAULT_MODEL
        
    def verify_token(self, token: str) -> bool:
        """
        éªŒè¯Tokenæ˜¯å¦æœ‰æ•ˆ
        é€šè¿‡è¯·æ±‚ /api/v1/chats/?page=1 æ¥å£æµ‹è¯•
        """
        import cloudscraper
        
        if not token or len(token) < 50:
            return False
            
        scraper = cloudscraper.create_scraper()
        headers = {
            "Authorization": f"Bearer {token}",
            "Accept": "application/json",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        
        try:
            resp = scraper.get(f"{self.base_url}/api/v1/chats/?page=1", headers=headers, timeout=10)
            return resp.status_code == 200
        except Exception as e:
            logger.error(f"TokenéªŒè¯å¤±è´¥: {e}")
            return False

    async def chat_completion(self, request_data: dict, token: str):
        """
        èŠå¤©å®Œæˆæ¥å£ - éµå¾ª Zai.is çœŸå® API æµç¨‹
        
        æ”¯æŒçš„æ¨¡å‹ï¼š
        - gemini-3-pro-image-preview (Nano Banana Pro)
        - gemini-2.5-pro (Gemini 2.5 Pro)
        - claude-opus-4-20250514 (Claude Opus 4)
        - claude-sonnet-4-5-20250929 (Claude Sonnet 4.5)
        - claude-sonnet-4-20250514 (Claude Sonnet 4)
        - claude-haiku-4-5-20251001 (Claude Haiku 4.5)
        - o1-2024-12-17 (o1)
        - o3-pro-2025-06-10 (o3-pro)
        - grok-4-1-fast-reasoning (Grok 4.1 Fast)
        - grok-4-0709 (Grok 4)
        - o4-mini-2025-04-16 (o4-mini)
        - gpt-5-2025-08-07 (GPT-5)
        - gemini-2.5-flash-image (Nano Banana)
        
        æµç¨‹ï¼š
        1. POST /api/v1/chats/new - åˆ›å»ºå¯¹è¯
        2. POST /api/v1/chats/{chat_id} - æ›´æ–°å¯¹è¯
        3. POST /api/chat/completions - æµå¼è¯·æ±‚AIå›å¤
        4. POST /api/chat/completed - æ ‡è®°å®Œæˆ
        """
        if not token:
            yield f"data: {json.dumps({'error': 'No token provided'})}\n\n"
            return

        model = request_data.get("model", self.default_model)
        messages = request_data.get("messages", [])
        stream = request_data.get("stream", True)
        
        if not messages:
            yield f"data: {json.dumps({'error': 'No messages provided'})}\n\n"
            return
        
        # æ„é€ æ¶ˆæ¯å†å²
        user_msg_id = str(uuid.uuid4())
        assistant_msg_id = str(uuid.uuid4())
        timestamp = int(time.time())
        user_content = messages[-1]["content"]
        
        # æ ¹æ®æ¨¡å‹åç§°è®¾ç½®æ¨¡å‹æ˜¾ç¤ºåç§°
        model_display_names = {
            "gemini-3-pro-image-preview": "Nano Banana Pro",
            "gemini-2.5-pro": "Gemini 2.5 Pro",
            "claude-opus-4-20250514": "Claude Opus 4",
            "claude-sonnet-4-5-20250929": "Claude Sonnet 4.5",
            "claude-sonnet-4-20250514": "Claude Sonnet 4",
            "claude-haiku-4-5-20251001": "Claude Haiku 4.5",
            "o1-2024-12-17": "o1",
            "o3-pro-2025-06-10": "o3-pro",
            "grok-4-1-fast-reasoning": "Grok 4.1 Fast",
            "grok-4-0709": "Grok 4",
            "o4-mini-2025-04-16": "o4-mini",
            "gpt-5-2025-08-07": "GPT-5",
            "gemini-2.5-flash-image": "Nano Banana"
        }
        
        model_name = model_display_names.get(model, model)
        
        # æ„é€  Zai.is æ ¼å¼çš„æ¶ˆæ¯å¯¹è±¡
        zai_messages = {
            user_msg_id: {
                "id": user_msg_id,
                "parentId": None,
                "childrenIds": [assistant_msg_id],
                "role": "user",
                "content": user_content,
                "timestamp": timestamp,
                "models": [model]
            },
            assistant_msg_id: {
                "parentId": user_msg_id,
                "id": assistant_msg_id,
                "childrenIds": [],
                "role": "assistant",
                "content": "",
                "model": model,
                "modelName": model_name,
                "modelIdx": 0,
                "timestamp": timestamp
            }
        }
        
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json",
            "Accept": "*/*",
            "Origin": "https://zai.is",
            "Referer": "https://zai.is/",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36"
        }

        async with httpx.AsyncClient(timeout=120) as client:
            try:
                # æ­¥éª¤1ï¼šåˆ›å»ºæ–°å¯¹è¯
                logger.debug(f"ğŸ“ æ­¥éª¤1: åˆ›å»ºæ–°å¯¹è¯ ({model})...")
                new_chat_payload = {
                    "chat": {
                        "id": "",
                        "title": "æ–°å¯¹è¯",
                        "models": [model],
                        "params": {},
                        "history": {
                            "messages": zai_messages,
                            "currentId": assistant_msg_id
                        },
                        "messages": list(zai_messages.values()),
                        "tags": [],
                        "timestamp": timestamp * 1000
                    },
                    "folder_id": None
                }
                
                resp1 = await client.post(
                    f"{self.base_url}/api/v1/chats/new",
                    json=new_chat_payload,
                    headers=headers
                )
                
                if resp1.status_code == 401:
                    yield f"data: {json.dumps({'error': 'Tokenæ— æ•ˆæˆ–å·²è¿‡æœŸ'})}\n\n"
                    return
                
                resp1.raise_for_status()
                chat_data = resp1.json()
                chat_id = chat_data.get("id")
                logger.success(f"âœ… å¯¹è¯åˆ›å»ºæˆåŠŸ: {chat_id}")
                
                # æ­¥éª¤2ï¼šå‘èµ·æµå¼è¡¥å…¨
                logger.debug(f"ğŸ’¬ æ­¥éª¤2: å‘èµ·AIè¯·æ±‚ ({model})...")
                completion_payload = {
                    "stream": True,
                    "model": model,
                    "messages": [{"role": "user", "content": user_content, "extensions": {}}],
                    "params": {},
                    "tool_servers": [],
                    "features": {
                        "image_generation": False,
                        "code_interpreter": False,
                        "web_search": False
                    },
                    "variables": {
                        "{{CURRENT_DATETIME}}": time.strftime("%Y-%m-%d %H:%M:%S"),
                        "{{CURRENT_DATE}}": time.strftime("%Y-%m-%d"),
                        "{{CURRENT_TIME}}": time.strftime("%H:%M:%S"),
                        "{{CURRENT_WEEKDAY}}": time.strftime("%A"),
                        "{{CURRENT_TIMEZONE}}": "Asia/Shanghai",
                        "{{USER_LANGUAGE}}": "zh-CN"
                    }
                }
                
                # å‘èµ·æµå¼è¯·æ±‚
                async with client.stream(
                    "POST",
                    f"{self.base_url}/api/chat/completions",
                    json=completion_payload,
                    headers=headers
                ) as resp2:
                    request_id = f"chatcmpl-{uuid.uuid4()}"
                    full_content = ""
                    
                    logger.debug(f"ğŸ“Š å¼€å§‹æ¥æ”¶SSEæµæ•°æ®...")
                    
                    # è¯»å–SSEæµ
                    async for line in resp2.aiter_lines():
                        if not line or line.startswith(":"):
                            continue
                        
                        if line.startswith("data: "):
                            data_str = line[6:]
                            
                            if data_str == "[DONE]":
                                logger.debug(f"âœ… SSEæµç»“æŸæ ‡è®°æ”¶åˆ°")
                                break
                            
                            try:
                                chunk_data = json.loads(data_str)
                                
                                # è®°å½•åŸå§‹å“åº”æ•°æ®ç”¨äºè°ƒè¯•
                                logger.debug(f"ğŸ” åŸå§‹å“åº”æ•°æ®: {json.dumps(chunk_data, ensure_ascii=False)[:200]}...")
                                
                                # å¯¹äº Zai çš„å“åº”æ ¼å¼ï¼Œæ²¡æœ‰ choices å­—æ®µï¼Œç›´æ¥å¤„ç† content
                                if "choices" in chunk_data and chunk_data["choices"]:
                                    # æ—§æ ¼å¼ï¼Œä¿æŒå…¼å®¹æ€§
                                    delta = chunk_data["choices"][0].get("delta", {})
                                    content = delta.get("content", "")
                                else:
                                    # Zai çš„æ–°æ ¼å¼ï¼šç›´æ¥åœ¨é¡¶å±‚æœ‰ content
                                    content = chunk_data.get("content", "")
                                    if not content:
                                        # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯èƒ½çš„å­—æ®µ
                                        choices = chunk_data.get("choices", [])
                                        if choices and "delta" in choices[0]:
                                            content = choices[0]["delta"].get("content", "")
                                
                                if content:
                                    logger.debug(f"ğŸ“ å¤„ç†å†…å®¹ç‰‡æ®µ: {content[:200]}...")
                                    
                                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡URLï¼Œå¦‚æœæ˜¯åˆ™è®°å½•æ£€æµ‹åˆ°çš„å›¾ç‰‡
                                    if "![image]" in content:
                                        logger.success(f"ğŸ–¼ï¸ æ£€æµ‹åˆ°å›¾ç‰‡URL: {content}")
                                    
                                    full_content += content
                                    
                                    # è½¬æ¢ä¸ºOpenAIæ ¼å¼
                                    openai_chunk = create_chat_completion_chunk(request_id, model, content)
                                    
                                    logger.debug(f"ğŸ“¤ å‘é€SSEå—: {json.dumps(openai_chunk, ensure_ascii=False)[:200]}...")
                                    yield f"data: {json.dumps(openai_chunk)}\n\n"
                            except Exception as e:
                                logger.error(f"å¤„ç†SSEæ•°æ®æ—¶å‡ºé”™: {e}, æ•°æ®: {data_str[:100]}")
                                # ç»§ç»­å¤„ç†å…¶ä»–æ•°æ®
                                pass
                    
                    # å‘é€ç»“æŸæ ‡è®°
                    final_chunk = create_chat_completion_chunk(request_id, model, "", "stop")
                    yield f"data: {json.dumps(final_chunk)}\n\n"
                    yield "data: [DONE]\n\n"
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡å¹¶è®°å½•
                    if "![image]" in full_content:
                        logger.success(f"âœ… AIå“åº”å®Œæˆï¼ŒåŒ…å«å›¾ç‰‡ï¼Œå…± {len(full_content)} å­—ç¬¦")
                    else:
                        logger.success(f"âœ… AIå“åº”å®Œæˆï¼Œå…± {len(full_content)} å­—ç¬¦")

            except Exception as e:
                logger.error(f"APIè¯·æ±‚å¤±è´¥: {e}")
                error_chunk = create_chat_completion_chunk("error", model, f"Error: {str(e)}")
                yield f"data: {json.dumps(error_chunk)}\n\n"
                yield "data: [DONE]\n\n"
    
    def _extract_ai_response(self, data):
        """ä»Zai APIå“åº”ä¸­æå–AIå›å¤"""
        try:
            # æ ¹æ®å®é™…å“åº”ç»“æ„è°ƒæ•´
            # è¿™é‡Œä½¿ç”¨é€šç”¨é€»è¾‘
            if isinstance(data, dict):
                if 'choices' in data and data['choices']:
                    return data['choices'][0].get('message', {}).get('content', '')
                elif 'content' in data:
                    return data['content']
            
            # é»˜è®¤è¿”å›æˆåŠŸæ¶ˆæ¯
            return "Zai API è°ƒç”¨æˆåŠŸã€‚å“åº”ç»“æ„å¯èƒ½éœ€è¦æ ¹æ®å®é™…APIè°ƒæ•´ã€‚"
            
        except Exception as e:
            logger.error(f"æå–AIå›å¤å¤±è´¥: {e}")
            return "æœªèƒ½æå–AIå›å¤"
